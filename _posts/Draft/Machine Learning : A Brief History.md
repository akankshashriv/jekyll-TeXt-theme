In this series of posts, I will explore the theory and applications of machine learning from a historical lens. I have often found myself intrigued by how the current state-of-the-art algorithms came to be and how the field evolved. It's a good idea to understand the evolution of a field in order to develop a solid theoretical foundation.

This series focuses on the timeline of Machine Learning up to the decade 2010s - primary contributions and seminal papers that have given us algorithms like Regression, Decision trees, and Neural Networks.

The idea is simple - know how and why an algorithm was developed, understand the theory and applications, and learn about the drawbacks. Imagine a tree with the root node 

## Contents
1. The very beginning - 1950s [PAC Model, VC Theory, Perceptrons]
2. 1960s - The Bayesian Era
3. The AI Winter of 1970s
4. 

> *The name of the series is inspired by my current favorite [non-fiction series on humanity](https://www.goodreads.com/book/show/34066641-sapiens-and-homo-deus) by Yuval Noah Harari.*
<!--stackedit_data:
eyJwcm9wZXJ0aWVzIjoibGF5b3V0OiBhcnRpY2xlXG50aXRsZT
ogXCJNYWNoaW5lIExlYXJuaW5nOiBBIEJyaWVmIEhpc3Rvcnlc
Ilxuc2lkZWJhcjpcbiAgbmF2OiBsYXlvdXRzXG4iLCJoaXN0b3
J5IjpbMTI4NDg2NTExMV19
-->